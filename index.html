<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rafiki Meeting Agent</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #eee;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
        }
        .container { text-align: center; padding: 40px; }
        .logo { font-size: 80px; margin-bottom: 20px; }
        .title {
            font-size: 32px; font-weight: 600; margin-bottom: 10px;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text; -webkit-text-fill-color: transparent;
        }
        .status { font-size: 18px; color: #888; margin-bottom: 30px; }
        .indicator {
            display: inline-block; width: 12px; height: 12px; border-radius: 50%;
            background: #f39c12; margin-right: 8px; animation: pulse 2s infinite;
        }
        .indicator.listening { background: #3498db; }
        .indicator.speaking { background: #2ecc71; animation: none; }
        .indicator.connected { background: #2ecc71; }
        .indicator.error { background: #e74c3c; animation: none; }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
        #debug {
            position: fixed; bottom: 10px; left: 10px; right: 10px;
            font-size: 11px; color: #aaa; max-height: 150px; overflow-y: auto;
            font-family: monospace; background: rgba(0,0,0,0.7); padding: 10px;
            border-radius: 5px;
        }
        .waveform {
            width: 200px; height: 60px; margin: 20px auto;
            display: flex; align-items: center; justify-content: center; gap: 4px;
        }
        .bar {
            width: 6px; background: #667eea; border-radius: 3px;
            animation: wave 1s ease-in-out infinite;
        }
        .bar:nth-child(1) { animation-delay: 0s; height: 20px; }
        .bar:nth-child(2) { animation-delay: 0.1s; height: 35px; }
        .bar:nth-child(3) { animation-delay: 0.3s; height: 50px; }
        .bar:nth-child(4) { animation-delay: 0.2s; height: 35px; }
        .bar:nth-child(5) { animation-delay: 0.4s; height: 20px; }
        @keyframes wave {
            0%, 100% { transform: scaleY(0.5); }
            50% { transform: scaleY(1); }
        }
        .waveform.idle .bar { animation: none; transform: scaleY(0.3); }
    </style>
</head>
<body>
    <div class="container">
        <div class="logo">ü¶Å</div>
        <h1 class="title">Rafiki</h1>
        <div class="waveform idle" id="waveform">
            <div class="bar"></div>
            <div class="bar"></div>
            <div class="bar"></div>
            <div class="bar"></div>
            <div class="bar"></div>
        </div>
        <p class="status">
            <span class="indicator" id="statusIndicator"></span>
            <span id="statusText">Initializing...</span>
        </p>
    </div>
    <div id="debug"></div>

    <script type="module">
        // ========== Configuration ==========
        const AGENT_ID = 'agent_5801kdgpnzv8e3qvqq4r18k7v7p7';

        // ========== UI Elements ==========
        const statusText = document.getElementById('statusText');
        const statusIndicator = document.getElementById('statusIndicator');
        const waveform = document.getElementById('waveform');
        const debug = document.getElementById('debug');

        // ========== Logging ==========
        function log(msg, type = 'info') {
            const timestamp = new Date().toLocaleTimeString();
            console.log(`[Rafiki ${type}]`, msg);
            const line = document.createElement('div');
            line.style.color = type === 'error' ? '#e74c3c' : type === 'success' ? '#2ecc71' : '#aaa';
            line.textContent = `${timestamp} ${msg}`;
            debug.appendChild(line);
            debug.scrollTop = debug.scrollHeight;
            if (debug.children.length > 30) debug.removeChild(debug.firstChild);
        }

        function setStatus(text, state = 'default') {
            statusText.textContent = text;
            statusIndicator.className = 'indicator ' + state;
            waveform.className = 'waveform ' + (state === 'speaking' ? '' : 'idle');
        }

        // ========== Audio Context for Output ==========
        // This is THE KEY - Recall.ai captures audio from AudioContext destination
        let audioContext = null;
        let nextPlayTime = 0;

        async function initAudioContext() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });
                log('AudioContext created: ' + audioContext.state);
            }

            if (audioContext.state === 'suspended') {
                await audioContext.resume();
                log('AudioContext resumed');
            }
            return audioContext;
        }

        // ========== PCM Audio Playback via Web Audio API ==========
        async function playPCMAudio(base64Audio, sampleRate = 16000) {
            try {
                const ctx = await initAudioContext();

                // Decode base64 to bytes
                const binaryString = atob(base64Audio);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // Convert Int16 PCM to Float32
                const int16 = new Int16Array(bytes.buffer);
                const float32 = new Float32Array(int16.length);
                for (let i = 0; i < int16.length; i++) {
                    float32[i] = int16[i] / 32768.0;
                }

                // Create audio buffer
                const audioBuffer = ctx.createBuffer(1, float32.length, sampleRate);
                audioBuffer.getChannelData(0).set(float32);

                // Schedule playback for gapless audio
                const source = ctx.createBufferSource();
                source.buffer = audioBuffer;

                const gainNode = ctx.createGain();
                gainNode.gain.value = 1.0;

                source.connect(gainNode);
                gainNode.connect(ctx.destination);

                // Gapless scheduling
                const startTime = Math.max(ctx.currentTime, nextPlayTime);
                source.start(startTime);
                nextPlayTime = startTime + audioBuffer.duration;

                return audioBuffer.duration;
            } catch (e) {
                log('Audio error: ' + e.message, 'error');
                return 0;
            }
        }

        // ========== Microphone Capture ==========
        async function getMicrophone() {
            log('Requesting microphone...');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                log('Microphone ready', 'success');
                return stream;
            } catch (e) {
                log('Mic error: ' + e.message, 'error');
                throw e;
            }
        }

        // ========== WebSocket to ElevenLabs ==========
        let ws = null;
        let isConnected = false;

        async function connectToElevenLabs() {
            setStatus('Connecting...', 'default');

            try {
                await initAudioContext();
                const micStream = await getMicrophone();

                // Connect WebSocket
                const wsUrl = `wss://api.elevenlabs.io/v1/convai/conversation?agent_id=${AGENT_ID}`;
                log('Connecting to ElevenLabs...');

                ws = new WebSocket(wsUrl);

                ws.onopen = () => {
                    log('Connected!', 'success');
                    isConnected = true;
                    setStatus('Listening...', 'listening');
                    startAudioCapture(micStream);
                };

                ws.onmessage = (event) => {
                    try {
                        const msg = JSON.parse(event.data);
                        handleWSMessage(msg);
                    } catch (e) {
                        log('Parse error', 'error');
                    }
                };

                ws.onerror = (e) => {
                    log('WS error', 'error');
                    setStatus('Error', 'error');
                };

                ws.onclose = () => {
                    log('Disconnected, reconnecting in 3s...');
                    isConnected = false;
                    setStatus('Reconnecting...', 'error');
                    setTimeout(connectToElevenLabs, 3000);
                };

            } catch (e) {
                log('Failed: ' + e.message, 'error');
                setStatus('Failed, retrying...', 'error');
                setTimeout(connectToElevenLabs, 5000);
            }
        }

        function handleWSMessage(msg) {
            switch (msg.type) {
                case 'conversation_initiation_metadata':
                    log('Session: ' + msg.conversation_id);
                    break;

                case 'audio':
                    // RAFIKI IS SPEAKING - play via Web Audio API
                    if (msg.audio?.chunk) {
                        setStatus('Speaking...', 'speaking');
                        playPCMAudio(msg.audio.chunk, msg.audio.sample_rate || 16000);
                    }
                    break;

                case 'agent_response':
                    if (msg.agent_response) {
                        log('Rafiki: ' + msg.agent_response.substring(0, 60));
                    }
                    break;

                case 'user_transcript':
                    if (msg.user_transcript) {
                        log('You: ' + msg.user_transcript.substring(0, 60));
                    }
                    break;

                case 'agent_response_end':
                    setTimeout(() => setStatus('Listening...', 'listening'), 500);
                    break;

                case 'ping':
                    if (ws?.readyState === WebSocket.OPEN) {
                        ws.send(JSON.stringify({ type: 'pong' }));
                    }
                    break;

                case 'error':
                    log('Error: ' + (msg.message || msg.error), 'error');
                    break;
            }
        }

        function startAudioCapture(stream) {
            const captureCtx = new AudioContext({ sampleRate: 16000 });
            const source = captureCtx.createMediaStreamSource(stream);
            const processor = captureCtx.createScriptProcessor(4096, 1, 1);

            processor.onaudioprocess = (e) => {
                if (!isConnected || ws?.readyState !== WebSocket.OPEN) return;

                const input = e.inputBuffer.getChannelData(0);

                // Convert Float32 to Int16 PCM
                const int16 = new Int16Array(input.length);
                for (let i = 0; i < input.length; i++) {
                    const s = Math.max(-1, Math.min(1, input[i]));
                    int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                }

                // Base64 encode
                const uint8 = new Uint8Array(int16.buffer);
                let binary = '';
                for (let i = 0; i < uint8.length; i++) {
                    binary += String.fromCharCode(uint8[i]);
                }

                ws.send(JSON.stringify({
                    type: 'audio',
                    audio: { chunk: btoa(binary), sample_rate: 16000 }
                }));
            };

            source.connect(processor);
            processor.connect(captureCtx.destination);
            log('Audio capture started', 'success');
        }

        // ========== Keep AudioContext alive ==========
        setInterval(async () => {
            if (audioContext?.state === 'suspended') {
                await audioContext.resume();
            }
        }, 3000);

        // ========== AUTO-START ==========
        log('Rafiki Meeting Agent v2 loaded');
        log('Auto-starting in 1 second...');

        setTimeout(() => {
            connectToElevenLabs();
        }, 1000);
    </script>
</body>
</html>
